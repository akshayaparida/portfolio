import { LearningModule } from "@/types/learning";

export const indexingStorageModule: LearningModule = {
  id: "indexing-storage",
  title: "Indexing & File Organization",
  description:
    "B+ Trees, hashing, file organization, and query optimization for data engineering",
  status: "in-progress",
  detailedContent: `# Indexing & File Organization

Efficient data storage and retrieval are crucial for database performance. This module covers indexing techniques, file organization methods, and query optimizationâ€”essential skills for data engineering roles.

## ğŸ¯ What You'll Learn

| # | Topic | Skill |
|:--|:------|:------|
| 1 | **File Organization** | Heap, Sequential, Hashed |
| 2 | **Indexing Basics** | Dense vs Sparse, Primary vs Secondary |
| 3 | **B+ Trees** | Structure, insertion, deletion, range queries |
| 4 | **Hashing** | Static vs Dynamic, Extendible Hashing |
| 5 | **Query Optimization** | Cost models, join algorithms |

---

## 1. File Organization

**How data is physically stored on disk affects performance.**

\`\`\`text path=null start=null
Storage Hierarchy:
                    Speed      Capacity
CPU Registers       ~1 ns      ~KB
L1/L2/L3 Cache     ~10 ns     ~MB
Main Memory (RAM)   ~100 ns    ~GB
SSD                 ~100 Î¼s    ~TB
HDD                 ~10 ms     ~TB

Database files live on disk â†’ Minimize disk I/O!
\`\`\`

**File Organization Types:**

| Type | Description | Best For |
|:-----|:------------|:---------|
| Heap | Records placed anywhere with space | Insert-heavy, full scans |
| Sequential | Records sorted by key | Range queries |
| Hashed | Records placed by hash function | Equality lookups |
| Clustered | Related records stored together | Join operations |

\`\`\`python path=null start=null
# Heap File Organization
# + Fast inserts (append anywhere)
# + Good for small tables
# - Slow search O(n) - must scan all

# Sequential File Organization
# + Fast range queries (sorted)
# + Binary search O(log n)
# - Slow inserts (must maintain order)

# Hash File Organization
# + O(1) average for equality lookup
# - No range queries
# - May need rehashing as data grows
\`\`\`

---

## 2. Indexing Fundamentals

**Index:** A data structure that speeds up data retrieval at the cost of additional storage and write overhead.

\`\`\`text path=null start=null
Without Index:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Full Table Scan: O(n)               â”‚
â”‚  Check every row to find matches     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With Index:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Index Lookup: O(log n)              â”‚
â”‚  Go directly to matching rows        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

**Index Classifications:**

| Classification | Types |
|:---------------|:------|
| By Structure | B+ Tree, Hash, Bitmap |
| By Density | Dense (all keys), Sparse (some keys) |
| By Key | Primary (on PK), Secondary (on other cols) |
| By Clustering | Clustered (sorted by index), Non-clustered |

**Dense vs Sparse Index:**

\`\`\`text path=null start=null
DENSE INDEX:
Entry for EVERY search key value
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10 â†’ #1   â”‚     â”‚ #1: {10, Alice}   â”‚
â”‚ 20 â†’ #2   â”‚ â”€â”€â†’ â”‚ #2: {20, Bob}     â”‚
â”‚ 30 â†’ #3   â”‚     â”‚ #3: {30, Charlie} â”‚
â”‚ 40 â†’ #4   â”‚     â”‚ #4: {40, Diana}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Index              Data File

SPARSE INDEX:
Entry for FIRST key in each block (requires sorted data)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10 â†’ Block1â”‚     â”‚ Block1: 10,11,12  â”‚
â”‚ 40 â†’ Block2â”‚ â”€â”€â†’ â”‚ Block2: 40,41,42  â”‚
â”‚ 70 â†’ Block3â”‚     â”‚ Block3: 70,71,72  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

**Primary vs Secondary Index:**

\`\`\`text path=null start=null
PRIMARY INDEX:
â€¢ On ordering key (data file sorted by this key)
â€¢ Usually sparse
â€¢ One per table

SECONDARY INDEX:
â€¢ On non-ordering field
â€¢ Always dense (data not sorted by this key)
â€¢ Multiple allowed per table

Example:
Employee table sorted by emp_id
â€¢ Primary index on emp_id (sparse OK)
â€¢ Secondary index on dept_id (must be dense)
\`\`\`

---

## 3. B+ Tree Index

**Most important index structure in databases!**

\`\`\`text path=null start=null
B+ Tree Properties:
â€¢ Self-balancing tree
â€¢ All data in leaf nodes (internal = navigation only)
â€¢ Leaf nodes linked (for range queries)
â€¢ High fanout â†’ short height â†’ few disk I/Os

Order = m (max children per node)
â€¢ Each node: ceil(m/2) to m children
â€¢ Root: 2 to m children
â€¢ Leaf: ceil((m-1)/2) to (m-1) keys
\`\`\`

**B+ Tree Structure:**

\`\`\`text path=null start=null
                    [30 | 70]                 â† Internal (root)
                   /    |    \\ 
                 /      |      \\
          [10|20]    [40|50|60]   [80|90]     â† Internal
          /  |  \\      / | | \\      / | \\
         /   |   \\    /  | |  \\    /  |  \\
        â†“    â†“    â†“  â†“   â†“ â†“   â†“  â†“   â†“   â†“
       [Leaf nodes with actual data, linked together]
       
       Leaf: [5|10] â†” [15|20|25] â†” [30|35] â†” ... 
\`\`\`

**B+ Tree Operations:**

\`\`\`python path=null start=null
# SEARCH (key = 45):
# 1. Start at root [30|70]
# 2. 30 < 45 < 70, go middle child [40|50|60]
# 3. 40 < 45 < 50, go second child
# 4. Reach leaf, search for 45
# Time: O(log_m n) where m = fanout

# INSERT (key = 55):
# 1. Find correct leaf
# 2. If space: insert in sorted order
# 3. If full: SPLIT leaf
#    - Move half keys to new leaf
#    - Insert separator key to parent
#    - If parent full: split propagates up

# DELETE (key = 45):
# 1. Find and remove from leaf
# 2. If node underflows (< ceil((m-1)/2) keys):
#    - Try to borrow from sibling
#    - Or merge with sibling
# 3. Merge may propagate to parent
\`\`\`

**B+ Tree Example:**

\`\`\`sql path=null start=null
-- Creating B+ Tree index
CREATE INDEX idx_salary ON Employee(salary);

-- Query using index
SELECT * FROM Employee WHERE salary = 50000;
-- Uses index: O(log n) instead of O(n)

-- Range query (uses linked leaves)
SELECT * FROM Employee WHERE salary BETWEEN 40000 AND 60000;
-- Find 40000 in tree, then scan linked leaves until 60000
\`\`\`

**Why B+ Tree over Binary Tree?**

| Aspect | Binary Tree | B+ Tree |
|:-------|:------------|:--------|
| Fanout | 2 | 100-1000 |
| Height for 1M rows | ~20 | ~3-4 |
| Disk I/O per search | ~20 | ~3-4 |
| Range queries | Hard | Easy (linked leaves) |

---

## 4. Hash-Based Indexing

**Excellent for equality queries, not for range queries.**

**Static Hashing:**

\`\`\`text path=null start=null
hash(key) = key mod num_buckets

Example: 5 buckets
hash(12) = 12 mod 5 = 2  â†’ Bucket 2
hash(47) = 47 mod 5 = 2  â†’ Bucket 2 (collision!)
hash(35) = 35 mod 5 = 0  â†’ Bucket 0

Bucket 0: [35, ...]
Bucket 1: []
Bucket 2: [12, 47, ...]  â† Overflow chain
Bucket 3: []
Bucket 4: []

Problem: Fixed buckets don't scale well!
\`\`\`

**Extendible Hashing:**

\`\`\`text path=null start=null
Dynamic hashing - grows/shrinks as needed

Components:
â€¢ Global Depth (d): Bits used from hash to index
â€¢ Local Depth: Bits used by each bucket
â€¢ Directory: Points to buckets (size = 2^d)

Example: Global depth = 2 (4 directory entries)
Hash(key) â†’ Binary â†’ Use last 2 bits

Directory:        Buckets:
  00 â”€â”€â”€â”€â”€â”€â†’ [A, B]  local depth = 2
  01 â”€â”€â”€â”€â”€â”€â†’ [C, D]  local depth = 2  
  10 â”€â”
  11 â”€â”´â”€â”€â”€â”€â†’ [E, F]  local depth = 1

When bucket overflows:
1. If local depth < global depth: Just split bucket
2. If local depth = global depth: Double directory first
\`\`\`

**Linear Hashing:**

\`\`\`text path=null start=null
Grows one bucket at a time (no directory)

â€¢ Split pointer (p) indicates next bucket to split
â€¢ Two hash functions: h0 and h1
â€¢ When p reaches end, increment level

Growth: Triggered by overflow or load factor
Advantage: No directory, gradual growth
\`\`\`

---

## 5. Query Optimization

**Query Processing Pipeline:**

\`\`\`text path=null start=null
SQL Query
    â†“
Parser (Syntax check)
    â†“
Optimizer (Generate plan)
    â†“
Execution Engine
    â†“
Results

Optimizer considers:
â€¢ Available indexes
â€¢ Table statistics
â€¢ Join order
â€¢ Algorithm choices
\`\`\`

**Cost Estimation:**

\`\`\`text path=null start=null
Cost = # of disk I/Os (primary factor)

Key Statistics:
â€¢ n(R) = Number of tuples in R
â€¢ b(R) = Number of blocks/pages
â€¢ V(A,R) = Number of distinct values of A in R

Selection Selectivity:
Ïƒ_{A=v}(R) â‰ˆ n(R) / V(A,R) tuples

Example:
Employee has 10,000 rows, 100 departments
SELECT * WHERE dept_id = 5
Estimated: 10,000/100 = 100 rows
\`\`\`

**Join Algorithms:**

\`\`\`python path=null start=null
# 1. NESTED LOOP JOIN
# For each tuple r in R:
#     For each tuple s in S:
#         if r.A = s.A: output (r, s)
# Cost: O(n * m) comparisons
# Disk I/O: b(R) + n(R) * b(S)

# 2. BLOCK NESTED LOOP
# For each BLOCK of R:
#     For each BLOCK of S:
#         For each tuple r in R-block:
#             For each tuple s in S-block:
#                 ...
# Cost: b(R) + b(R) * b(S) (better!)

# 3. INDEX NESTED LOOP
# For each tuple r in R:
#     Use index to find matching s in S
# Cost: b(R) + n(R) * (index lookup cost)

# 4. SORT-MERGE JOIN
# Sort both R and S on join attribute
# Merge sorted relations
# Cost: Sort + Merge = O(n log n + m log m)

# 5. HASH JOIN
# Build hash table on smaller relation
# Probe with tuples from larger relation
# Cost: O(n + m) if fits in memory
\`\`\`

**Join Order Optimization:**

\`\`\`sql path=null start=null
-- Query: SELECT * FROM A, B, C WHERE A.x = B.x AND B.y = C.y

-- Possible join orders:
-- (A â‹ˆ B) â‹ˆ C
-- (B â‹ˆ C) â‹ˆ A  
-- (A â‹ˆ C) â‹ˆ B
-- A â‹ˆ (B â‹ˆ C)
-- ... and more!

-- Optimizer picks order with lowest estimated cost
-- Uses dynamic programming or heuristics
-- Principle: Do selective operations first
\`\`\`

**EXPLAIN to View Query Plan:**

\`\`\`sql path=null start=null
EXPLAIN ANALYZE SELECT * FROM Employee WHERE salary > 50000;

-- Output shows:
-- - Access method (index scan vs sequential scan)
-- - Estimated rows
-- - Actual time
-- - Join methods used
\`\`\`

---

## TL;DR - Quick Reference

| Concept | Key Point |
|:--------|:----------|
| Heap File | Unordered, fast insert, slow search |
| Sequential | Sorted, good for ranges |
| Dense Index | Entry for every key |
| Sparse Index | Entry for first key per block |
| B+ Tree | Balanced, data in leaves, linked leaves |
| B+ Height | O(log_m n), typically 3-4 for millions of rows |
| Hash Index | O(1) equality, no ranges |
| Extendible Hash | Dynamic growth with directory |
| Query Cost | Minimize disk I/Os |
| Hash Join | Build on smaller, probe with larger |

---

## ğŸ“š Resources

- [Use The Index, Luke!](https://use-the-index-luke.com/) - SQL Indexing tutorial
- [B+ Tree Visualization](https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html) - Interactive
- [PostgreSQL EXPLAIN Guide](https://www.postgresql.org/docs/current/using-explain.html)
    `,
  subModules: [],
  practiceQuiz: [
    {
      id: "idx-q1",
      question: "B+ Trees store all data records in:",
      options: ["Root nodes", "Internal nodes", "Leaf nodes", "All nodes"],
      correctAnswer: 2,
      explanation:
        "B+ Tree Structure:\\n\\nâ€¢ Internal nodes: Only keys for navigation\\nâ€¢ Leaf nodes: All data records + linked for range queries\\n\\nThis differs from B-Trees which store data in all nodes.",
      difficulty: "easy",
    },
    {
      id: "idx-q2",
      question: "Which index type is best for range queries?",
      options: [
        "Hash Index",
        "Bitmap Index",
        "B+ Tree Index",
        "All equally good",
      ],
      correctAnswer: 2,
      explanation:
        "Index Types for Ranges:\\n\\nâ€¢ B+ Tree: Excellent! Linked leaves allow sequential scan\\nâ€¢ Hash: Poor - designed for equality only\\nâ€¢ Bitmap: Good for low-cardinality columns\\n\\nB+ Tree is the default for most queries.",
      difficulty: "easy",
    },
    {
      id: "idx-q3",
      question: "A sparse index requires the data file to be:",
      options: [
        "Hashed",
        "Sorted on index key",
        "Clustered",
        "In heap organization",
      ],
      correctAnswer: 1,
      explanation:
        "Sparse vs Dense:\\n\\nâ€¢ Sparse: One entry per block (first key only)\\n  Requires SORTED data to work!\\n\\nâ€¢ Dense: Entry for every key value\\n  Works with unsorted data too.",
      difficulty: "medium",
    },
    {
      id: "idx-q4",
      question:
        "In extendible hashing, when a bucket overflows and local depth equals global depth:",
      options: [
        "Bucket is deleted",
        "Directory is doubled",
        "Linear probing starts",
        "Overflow chain created",
      ],
      correctAnswer: 1,
      explanation:
        "Extendible Hashing Overflow:\\n\\nâ€¢ If local depth < global depth: Just split bucket\\nâ€¢ If local depth = global depth: DOUBLE directory first, then split\\n\\nDirectory doubles in size (2^d â†’ 2^(d+1))",
      difficulty: "hard",
    },
    {
      id: "idx-q5",
      question:
        "The primary advantage of B+ trees over binary trees for disk-based indexing is:",
      options: [
        "Simpler implementation",
        "Higher fanout reducing disk I/O",
        "No need for balancing",
        "Smaller memory footprint",
      ],
      correctAnswer: 1,
      explanation:
        "B+ Tree Advantage:\\n\\nâ€¢ High fanout (100-1000 children)\\nâ€¢ Tree height of 3-4 for millions of rows\\nâ€¢ Each level = one disk I/O\\nâ€¢ Binary tree: Height ~20 = ~20 disk I/Os!",
      difficulty: "medium",
    },
    {
      id: "idx-q6",
      question: "Hash join is most efficient when:",
      options: [
        "Both tables are large",
        "Building hash table on smaller relation fits in memory",
        "Tables are sorted",
        "Using clustered index",
      ],
      correctAnswer: 1,
      explanation:
        "Hash Join Strategy:\\n\\nâ€¢ BUILD phase: Create hash table on smaller relation\\nâ€¢ PROBE phase: Scan larger relation, lookup in hash table\\n\\nBest when smaller table fits in memory!\\nCost: O(n + m) - linear in both sizes",
      difficulty: "medium",
    },
    {
      id: "idx-q7",
      question: "A secondary index must always be:",
      options: ["Sparse", "Dense", "Clustered", "On primary key"],
      correctAnswer: 1,
      explanation:
        "Index Density:\\n\\nâ€¢ Primary index: Can be sparse (data sorted by key)\\nâ€¢ Secondary index: MUST be dense\\n\\nWhy? Data not sorted by secondary key, so we need pointer to every matching row!",
      difficulty: "medium",
    },
    {
      id: "idx-q8",
      question: "In query optimization, the main cost factor is:",
      options: ["CPU cycles", "Memory usage", "Disk I/O", "Network latency"],
      correctAnswer: 2,
      explanation:
        "Database Cost Model:\\n\\nDisk I/O is orders of magnitude slower than memory:\\nâ€¢ Disk access: ~10ms\\nâ€¢ Memory access: ~100ns\\n\\nOptimizer minimizes disk block accesses!",
      difficulty: "easy",
    },
    {
      id: "idx-q9",
      question: "Nested loop join has worst-case complexity of:",
      options: ["O(n)", "O(n log n)", "O(n * m)", "O(n + m)"],
      correctAnswer: 2,
      explanation:
        "Join Complexities:\\n\\nâ€¢ Nested Loop: O(n * m) - compare every pair\\nâ€¢ Hash Join: O(n + m) - linear if fits in memory\\nâ€¢ Sort-Merge: O(n log n + m log m)\\n\\nNested loop is simple but expensive for large tables!",
      difficulty: "easy",
    },
    {
      id: "idx-q10",
      question: "A clustered index means:",
      options: [
        "Multiple indexes on same column",
        "Data stored in index order",
        "B+ tree structure",
        "Index on primary key",
      ],
      correctAnswer: 1,
      explanation:
        "Clustered vs Non-clustered:\\n\\nâ€¢ Clustered: Data PHYSICALLY sorted by index key\\n  Only ONE clustered index per table!\\n\\nâ€¢ Non-clustered: Index separate from data\\n  Multiple allowed",
      difficulty: "medium",
    },
  ],
};
